{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这篇论文主要通过**自然语言处理（NLP）和社会网络分析SNA**的方法，对《三体》系列小说中的人物关系进行量化研究，并结合女性主义理论进行解读。分析的核心包括以下几个方面："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1.数据分析方法概述**\n",
    "### **（1）文本数据预处理**\n",
    "1. **深度阅读文本，构建人物词典**\n",
    "   - 先手工整理人物名单，建立两份词典：\n",
    "     - **正式姓名词典**（如：罗辑、程心、叶文洁）\n",
    "     - **别称映射词典**（如：罗辑 -> 小罗、罗兄、罗教授）\n",
    "\n",
    "2. **实体识别**\n",
    "   - 使用**Python的NLP工具（如jieba、spaCy等）**进行**分词**和**实体识别**，提取小说中的人物名称。\n",
    "\n",
    "---\n",
    "\n",
    "### **（2）人物关系构建**\n",
    "1. **共现分析（Co-occurrence Analysis）**\n",
    "   - **定义人物关系：** 两个人物在小说**同一行**同时出现，视为存在一次联系。\n",
    "   - **建立共现矩阵：** 统计小说文本中人物的共现次数，形成**人物-人物共现矩阵**（即邻接矩阵）。\n",
    "\n",
    "2. **数据清洗**\n",
    "   - 过滤出现次数较少的人物，最终确定**180名人物**和**368对共现关系**。\n",
    "\n",
    "---\n",
    "\n",
    "### **（3）社会网络分析**\n",
    "1. **使用 Gephi 进行可视化**\n",
    "   - 导入清洗后的**人物-人物共现矩阵**，构建社交网络。\n",
    "   - **节点（Node）：** 代表小说中的角色。\n",
    "   - **边（Edge）：** 代表人物间的联系（共现次数）。\n",
    "   - 过滤掉**共现次数小于5的弱联系**，确保主要人物关系清晰可见。\n",
    "\n",
    "2. **计算社会网络中心性指标**\n",
    "   - **度中心性（Degree Centrality）**\n",
    "     - 计算角色的**直接连接数**，代表人物的影响力。\n",
    "     - 统计**度中心性最高的角色**，发现**智子、程心**等女性角色占据重要位置。\n",
    "\n",
    "   - **中介中心性（Betweenness Centrality）**\n",
    "     - 计算角色**在其他人物间的最短路径上**出现的次数，衡量其在网络中的“桥梁”作用。\n",
    "     - 发现**智子在整个社交网络中是最核心的节点**，连接多个主要角色。\n",
    "\n",
    "   - **特征向量中心性（Eigenvector Centrality）**\n",
    "     - 计算角色是否与其他**重要角色**有较多联系，衡量人物的社会影响力。\n",
    "     - 发现**智子、程心、叶文洁等女性角色在小说中具有很强的网络影响力**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2.实验流程**\n",
    "## **1. 数据准备**\n",
    "### **（1）所需数据**\n",
    "- **小说文本**：《三体》全书的文本数据（TXT格式）。\n",
    "- **人物词典**：\n",
    "  - **正式姓名词典**（如：罗辑、程心、叶文洁）\n",
    "  - **别称映射词典**（如：罗辑 -> 小罗、罗教授）\n",
    "- **共现矩阵**：\n",
    "  - **记录人物在文本中的共现次数**，即两个角色同时出现在**相同行**中。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import itertools\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取小说文本\n",
    "with open(\"san_ti.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.readlines()\n",
    "\n",
    "# 读取正式姓名词典\n",
    "with open(\"formal_names.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    formal_names = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# 读取别名映射词典\n",
    "alias_mapping = {}\n",
    "with open(\"alias_mapping.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        main_name, aliases = line.strip().split(\":\")\n",
    "        for alias in aliases.split(\",\"):\n",
    "            alias_mapping[alias.strip()] = main_name.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **（2）数据来源**\n",
    "1. **小说文本数据**\n",
    "   - **方式1（手动）：** 可以从电子书（如 Kindle、网盘资源）导出《三体》文本。\n",
    "   - **方式2（爬取）：** 可使用 Python 爬取在线小说网站（如起点、豆瓣读书）。\n",
    "   - **方式3（公开数据集）：** 查找 GitHub 或 NLP 公开数据资源。\n",
    "\n",
    "2. **人物词典**\n",
    "   - **手工整理**：《三体》中的人物可以手动提取，构建正式姓名词典。\n",
    "   - **自动生成**：\n",
    "     - 从小说文本中提取所有**高频人名**。\n",
    "     - 结合 NLP **共现分析**自动发现别称。\n",
    "\n",
    "3. **共现矩阵**\n",
    "   - **手工标注**：找出**主要角色的共现关系**，建立基础数据。\n",
    "   - **自动生成**：\n",
    "     - 使用 NLP 分词后，检测**人物名**是否在**同一行或相邻N行**出现。\n",
    "     - 统计**人物对Character Pairs**的共现次数。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. 数据预处理**\n",
    "### **（1）分词与实体识别**\n",
    "**目标：**\n",
    "- 使用 **jieba** 或 **HanLP** 进行**中文分词**，识别**人名**。\n",
    "- 过滤掉**非人名的词**，形成**正式姓名列表**。\n",
    "- （分词与别名替换）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载人物词典到 jieba\n",
    "jieba.load_userdict(\"formal_names.txt\")\n",
    "\n",
    "def replace_aliases(text, alias_mapping):\n",
    "    \"\"\" 替换文本中的别名为正式姓名 \"\"\"\n",
    "    for alias, main_name in alias_mapping.items():\n",
    "        text = text.replace(alias, main_name)\n",
    "    return text\n",
    "\n",
    "# 替换小说文本中的别名\n",
    "processed_text = [replace_aliases(line, alias_mapping) for line in text]\n",
    "\n",
    "# 统计人名出现频率\n",
    "char_counts = Counter()\n",
    "for line in processed_text:\n",
    "    words = pseg.cut(line)\n",
    "    for word, flag in words:\n",
    "        if flag == \"nr\" and word in formal_names:\n",
    "            char_counts[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **（2）共现矩阵构建**\n",
    "**目标：**\n",
    "- 计算**人物之间的共现次数**。\n",
    "- 统计两个人物**在同一行或相邻N行**出现的频率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 3  # 设置窗口大小\n",
    "co_occurrence = {char: {char2: 0 for char2 in formal_names} for char in formal_names}\n",
    "\n",
    "for i in range(len(processed_text)):\n",
    "    window_text = \" \".join(processed_text[i:i + window_size])\n",
    "    present_chars = [char for char in formal_names if char in window_text]\n",
    "    \n",
    "    for char1, char2 in itertools.combinations(present_chars, 2):\n",
    "        co_occurrence[char1][char2] += 1\n",
    "        co_occurrence[char2][char1] += 1\n",
    "\n",
    "# 转换为 DataFrame 并保存\n",
    "df_co_occurrence = pd.DataFrame(co_occurrence)\n",
    "df_co_occurrence.to_csv(\"co_occurrence_matrix.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. 社会网络分析**\n",
    "### **（1）使用 NetworkX 构建社交网络**\n",
    "**目标：**\n",
    "- 用 **NetworkX** 构建人物关系图。\n",
    "- 计算 **社交网络中心性指标**（度中心性、中介中心性、特征向量中心性）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "\n",
    "for character in df_co_occurrence.columns:\n",
    "    G.add_node(character, weight=df_co_occurrence[character].sum())\n",
    "\n",
    "for char1 in df_co_occurrence.columns:\n",
    "    for char2 in df_co_occurrence.columns:\n",
    "        weight = df_co_occurrence.loc[char1, char2]\n",
    "        if weight > 5:  # 过滤低频共现\n",
    "            G.add_edge(char1, char2, weight=weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **（2）计算中心性指标**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算中心性指标\n",
    "degree_centrality = nx.degree_centrality(G)\n",
    "betweenness_centrality = nx.betweenness_centrality(G)\n",
    "eigenvector_centrality = nx.eigenvector_centrality(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Gephi 可视化**\n",
    "### **（1）导出数据到 Gephi**\n",
    "- **Gephi** 是一个专业的数据可视化工具，可以加载 `.gexf` 文件，绘制人物关系图。\n",
    "- 通过调整**颜色、节点大小、边的权重**，可以直观分析**《三体》中的人物关系网**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(G, \"san_ti_network.gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Character    Degree  Betweenness  Eigenvector\n",
      "44         罗辑  0.232394     0.117930     0.348824\n",
      "40      军事执政官  0.218310     0.144006     0.277735\n",
      "116        智子  0.197183     0.066246     0.333098\n",
      "15        叶文洁  0.154930     0.095421     0.216419\n",
      "97         程心  0.147887     0.050368     0.229816\n",
      "36       核弹女孩  0.133803     0.040541     0.270506\n",
      "1          史强  0.119718     0.044090     0.186774\n",
      "0          汪淼  0.112676     0.029070     0.139902\n",
      "101       云天明  0.105634     0.028736     0.142989\n",
      "46   弗雷德里克·泰勒  0.098592     0.018579     0.195734\n"
     ]
    }
   ],
   "source": [
    "# 输出最高中心性角色\n",
    "centrality_df = pd.DataFrame({\n",
    "    \"Character\": list(degree_centrality.keys()),\n",
    "    \"Degree\": list(degree_centrality.values()),\n",
    "    \"Betweenness\": list(betweenness_centrality.values()),\n",
    "    \"Eigenvector\": list(eigenvector_centrality.values())\n",
    "})\n",
    "print(centrality_df.sort_values(by=\"Degree\", ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## **5.实验流程总结**\n",
    "✅ **数据准备**\n",
    "- 获取《三体》文本数据（TXT）。\n",
    "- 构建**人物词典**（正式姓名+别称映射）。\n",
    "- 统计**人物共现矩阵**。\n",
    "\n",
    "✅ **数据处理**\n",
    "- **分词+实体识别**（使用 NLP 提取人名）。\n",
    "- **统计共现次数**（计算两两角色的关系）。\n",
    "\n",
    "✅ **网络分析**\n",
    "- 使用 **NetworkX** 计算**度中心性、中介中心性、特征向量中心性**。\n",
    "- 发现《三体》中**智子、程心、叶文洁**等女性角色的核心地位。\n",
    "\n",
    "✅ **Gephi 可视化**\n",
    "- 生成 `.gexf` 文件，在 Gephi 中绘制社交网络。\n",
    "\n",
    "通过本实验，可以定量研究《三体》中的**人物社交网络**，并结合**女性主义理论**进行深入解读。\n",
    "# **3. 论文的核心观点总结**\n",
    "1. **人物网络分析方法**\n",
    "   - 通过NLP提取人物，并构建**共现矩阵**。\n",
    "   - 通过Python和Gephi构建**社交网络**并分析中心性。\n",
    "\n",
    "2. **女性角色的重要性**\n",
    "   - **智子、程心、叶文洁**等女性角色在**度中心性、中介中心性、特征向量中心性**等指标上排名前列。\n",
    "   - 说明她们在故事中的社交网络中占据**重要的资源和权力位置**。\n",
    "\n",
    "3. **女性主义视角**\n",
    "   - 论文通过波伏娃的女性主义理论，认为《三体》的女性角色成功突破了**传统父权社会的束缚**。\n",
    "   - 小说中的未来社会呈现**“女性化”趋势**，女性在社会网络中获得了更大的**话语权和影响力**。\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
